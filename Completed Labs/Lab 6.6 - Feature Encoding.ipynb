{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T23:24:44.710131Z",
     "start_time": "2019-05-26T23:24:44.669241Z"
    },
    "colab_type": "text",
    "id": "Xk8fq5PNZBis"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXEmJGi6ZBiu"
   },
   "source": [
    "# Lab 6.6\n",
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uIs6u55WZBiv"
   },
   "source": [
    "### Data\n",
    "\n",
    "**Predict the chronic kidney disease.**\n",
    "\n",
    "This dataset can be used to predict the chronic kidney disease and it can be collected from the hospital nearly 2 months of period.\n",
    "\n",
    "We use the following representation to collect the dataset \n",
    "- age\t-\tage\t\n",
    "- bp\t-\tblood pressure \n",
    "- sg\t-\tspecific gravity \n",
    "- al\t- albumin \n",
    "- su\t-\tsugar \n",
    "- rbc\t-\tred blood cells \n",
    "- pc\t-\tpus cell \n",
    "- pcc\t-\tpus cell clumps \n",
    "- ba\t-\tbacteria \n",
    "- bgr\t-\tblood glucose random \n",
    "- bu\t-\tblood urea \n",
    "- sc\t-\tserum creatinine \n",
    "- sod\t-\tsodium \n",
    "- pot\t-\tpotassium \n",
    "- hemo\t-\themoglobin \n",
    "- pcv\t-\tpacked cell volume \n",
    "- wc\t-\twhite blood cell count \n",
    "- rc\t-\tred blood cell count \n",
    "- htn\t-\thypertension \n",
    "- dm\t-\tdiabetes mellitus \n",
    "- cad\t-\tcoronary artery disease \n",
    "- appet\t-\tappetite \n",
    "- pe\t-\tpedal edema \n",
    "- ane\t-\tanemia \n",
    "- class\t-\tclass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[Chronic Kidney Disease DataSet](https://archive.ics.uci.edu/ml/datasets/chronic_kidney_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T07:39:24.374436Z",
     "start_time": "2019-05-27T07:39:24.366509Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Uv3dx6ClZBiw"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T23:51:34.682929Z",
     "start_time": "2019-05-26T23:51:34.678939Z"
    },
    "colab_type": "text",
    "id": "qCrSbU7lZBiz"
   },
   "source": [
    "#### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T07:39:40.506841Z",
     "start_time": "2019-05-27T07:39:40.502852Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "1keyNaMwZBi0"
   },
   "outputs": [],
   "source": [
    "# Read Data\n",
    "kidney_disease_csv = 'kidney_disease.csv'\n",
    "\n",
    "df = pd.read_csv(kidney_disease_csv, index_col = 'id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IR_aDbYyZBi3"
   },
   "source": [
    "#### 2. Perform EDA\n",
    "\n",
    "Perform EDA. Check null values. Impute if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>hemo</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.4</td>\n",
       "      <td>44</td>\n",
       "      <td>7800</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.3</td>\n",
       "      <td>38</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.6</td>\n",
       "      <td>31</td>\n",
       "      <td>7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>11.2</td>\n",
       "      <td>32</td>\n",
       "      <td>6700</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.6</td>\n",
       "      <td>35</td>\n",
       "      <td>7300</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
       "id                                                                          \n",
       "0   48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "1    7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "2   62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
       "3   48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
       "4   51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "      bgr    bu   sc    sod  pot  hemo pcv    wc   rc  htn   dm cad appet  \\\n",
       "id                                                                          \n",
       "0   121.0  36.0  1.2    NaN  NaN  15.4  44  7800  5.2  yes  yes  no  good   \n",
       "1     NaN  18.0  0.8    NaN  NaN  11.3  38  6000  NaN   no   no  no  good   \n",
       "2   423.0  53.0  1.8    NaN  NaN   9.6  31  7500  NaN   no  yes  no  poor   \n",
       "3   117.0  56.0  3.8  111.0  2.5  11.2  32  6700  3.9  yes   no  no  poor   \n",
       "4   106.0  26.0  1.4    NaN  NaN  11.6  35  7300  4.6   no   no  no  good   \n",
       "\n",
       "     pe  ane classification  \n",
       "id                           \n",
       "0    no   no            ckd  \n",
       "1    no   no            ckd  \n",
       "2    no  yes            ckd  \n",
       "3   yes  yes            ckd  \n",
       "4    no   no            ckd  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 400 entries, 0 to 399\n",
      "Data columns (total 25 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             391 non-null    float64\n",
      " 1   bp              388 non-null    float64\n",
      " 2   sg              353 non-null    float64\n",
      " 3   al              354 non-null    float64\n",
      " 4   su              351 non-null    float64\n",
      " 5   rbc             248 non-null    object \n",
      " 6   pc              335 non-null    object \n",
      " 7   pcc             396 non-null    object \n",
      " 8   ba              396 non-null    object \n",
      " 9   bgr             356 non-null    float64\n",
      " 10  bu              381 non-null    float64\n",
      " 11  sc              383 non-null    float64\n",
      " 12  sod             313 non-null    float64\n",
      " 13  pot             312 non-null    float64\n",
      " 14  hemo            348 non-null    float64\n",
      " 15  pcv             330 non-null    object \n",
      " 16  wc              295 non-null    object \n",
      " 17  rc              270 non-null    object \n",
      " 18  htn             398 non-null    object \n",
      " 19  dm              398 non-null    object \n",
      " 20  cad             398 non-null    object \n",
      " 21  appet           399 non-null    object \n",
      " 22  pe              399 non-null    object \n",
      " 23  ane             399 non-null    object \n",
      " 24  classification  400 non-null    object \n",
      "dtypes: float64(11), object(14)\n",
      "memory usage: 81.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change pcc,wc,rc to numeric\n",
    "\n",
    "df['pcv'] = pd.to_numeric(df['pcv'], errors ='coerce')\n",
    "df['wc'] = pd.to_numeric(df['wc'], errors ='coerce')\n",
    "df['rc'] = pd.to_numeric(df['rc'], errors ='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rbc               152\n",
       "rc                131\n",
       "wc                106\n",
       "pot                88\n",
       "sod                87\n",
       "pcv                71\n",
       "pc                 65\n",
       "hemo               52\n",
       "su                 49\n",
       "sg                 47\n",
       "al                 46\n",
       "bgr                44\n",
       "bu                 19\n",
       "sc                 17\n",
       "bp                 12\n",
       "age                 9\n",
       "ba                  4\n",
       "pcc                 4\n",
       "htn                 2\n",
       "dm                  2\n",
       "cad                 2\n",
       "appet               1\n",
       "pe                  1\n",
       "ane                 1\n",
       "classification      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values\n",
    "df.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age has [48.  7. 62. 51. 60. 68. 24. 52. 53. 50. 63. 40. 47. 61. 21. 42. 75. 69.\n",
      " nan 73. 70. 65. 76. 72. 82. 46. 45. 35. 54. 11. 59. 67. 15. 55. 44. 26.\n",
      " 64. 56.  5. 74. 38. 58. 71. 34. 17. 12. 43. 41. 57.  8. 39. 66. 81. 14.\n",
      " 27. 83. 30.  4.  3.  6. 32. 80. 49. 90. 78. 19.  2. 33. 36. 37. 23. 25.\n",
      " 20. 29. 28. 22. 79.] values.\n",
      "\n",
      "bp has [ 80.  50.  70.  90.  nan 100.  60. 110. 140. 180. 120.] values.\n",
      "\n",
      "sg has [1.02  1.01  1.005 1.015   nan 1.025] values.\n",
      "\n",
      "al has [ 1.  4.  2.  3.  0. nan  5.] values.\n",
      "\n",
      "su has [ 0.  3.  4.  1. nan  2.  5.] values.\n",
      "\n",
      "rbc has [nan 'normal' 'abnormal'] values.\n",
      "\n",
      "pc has ['normal' 'abnormal' nan] values.\n",
      "\n",
      "pcc has ['notpresent' 'present' nan] values.\n",
      "\n",
      "ba has ['notpresent' 'present' nan] values.\n",
      "\n",
      "bgr has [121.  nan 423. 117. 106.  74. 100. 410. 138.  70. 490. 380. 208.  98.\n",
      " 157.  76.  99. 114. 263. 173.  95. 108. 156. 264. 123.  93. 107. 159.\n",
      " 140. 171. 270.  92. 137. 204.  79. 207. 124. 144.  91. 162. 246. 253.\n",
      " 141. 182.  86. 150. 146. 425. 112. 250. 360. 163. 129. 133. 102. 158.\n",
      " 165. 132. 104. 127. 415. 169. 251. 109. 280. 210. 219. 295.  94. 172.\n",
      " 101. 298. 153.  88. 226. 143. 115.  89. 297. 233. 294. 323. 125.  90.\n",
      " 308. 118. 224. 128. 122. 214. 213. 268. 256.  84. 105. 288. 139.  78.\n",
      " 273. 242. 424. 303. 148. 160. 192. 307. 220. 447. 309.  22. 111. 261.\n",
      " 215. 234. 131. 352.  80. 239. 110. 130. 184. 252. 113. 230. 341. 255.\n",
      " 103. 238. 248. 120. 241. 269. 201. 203. 463. 176.  82. 119.  97.  96.\n",
      "  81. 116. 134.  85.  83.  87.  75.] values.\n",
      "\n",
      "bu has [ 36.   18.   53.   56.   26.   25.   54.   31.   60.  107.   55.   72.\n",
      "  86.   90.  162.   46.   87.   27.  148.  180.  163.    nan  50.   75.\n",
      "  45.   28.  155.   33.   39.  153.   29.   65.  103.   70.   80.   20.\n",
      " 202.   77.   89.   24.   17.   32.  114.   66.   38.  164.  142.   96.\n",
      " 391.   15.  111.   73.   19.   92.   35.   16.  139.   48.   85.   98.\n",
      " 186.   37.   47.   52.   82.   51.  106.   22.  217.   88.  118.   50.1\n",
      "  71.   34.   40.   21.  219.   30.  125.  166.   49.  208.  176.   68.\n",
      " 145.  165.  322.   23.  235.  132.   76.   42.   44.   41.  113.    1.5\n",
      " 146.   58.  133.  137.   67.  115.  223.   98.6 158.   94.   74.  150.\n",
      "  61.   57.   95.  191.   93.  241.   64.   79.  215.  309.   10. ] values.\n",
      "\n",
      "sc has [ 1.2   0.8   1.8   3.8   1.4   1.1  24.    1.9   7.2   4.    2.7   2.1\n",
      "  4.6   4.1   9.6   2.2   5.2   1.3   1.6   3.9  76.    7.7    nan  2.4\n",
      "  7.3   1.5   2.5   2.    3.4   0.7   1.   10.8   6.3   5.9   0.9   3.\n",
      "  3.25  9.7   6.4   3.2  32.    0.6   6.1   3.3   6.7   8.5   2.8  15.\n",
      "  2.9   1.7   3.6   5.6   6.5   4.4  10.2  11.5   0.5  12.2   5.3   9.2\n",
      " 13.8  16.9   6.    7.1  18.    2.3  13.   48.1  14.2  16.4   2.6   7.5\n",
      "  4.3  18.1  11.8   9.3   6.8  13.5  12.8  11.9  12.   13.4  15.2  13.3\n",
      "  0.4 ] values.\n",
      "\n",
      "sod has [  nan 111.  142.  104.  114.  131.  138.  135.  130.  141.  139.    4.5\n",
      " 136.  129.  140.  132.  133.  134.  125.  163.  137.  128.  143.  127.\n",
      " 146.  126.  122.  147.  124.  115.  145.  113.  120.  150.  144. ] values.\n",
      "\n",
      "pot has [ nan  2.5  3.2  4.   3.7  4.2  5.8  3.4  6.4  4.9  4.1  4.3  5.2  3.8\n",
      "  4.6  3.9  4.7  5.9  4.8  4.4  6.6 39.   5.5  5.   3.5  3.6  7.6  2.9\n",
      "  4.5  5.7  5.4  5.3 47.   6.3  5.1  5.6  3.   2.8  2.7  6.5  3.3] values.\n",
      "\n",
      "hemo has [15.4 11.3  9.6 11.2 11.6 12.2 12.4 10.8  9.5  9.4  9.7  9.8  5.6  7.6\n",
      " 12.6 12.1 12.7 10.3  7.7 10.9  nan 11.1  9.9 12.5 12.9 10.1 12.  13.\n",
      "  7.9  9.3 15.  10.   8.6 13.6 10.2 10.5  6.6 11.   7.5 15.6 15.2  4.8\n",
      "  9.1  8.1 11.9 13.5  8.3  7.1 16.1 10.4  9.2  6.2 13.9 14.1  6.  11.8\n",
      " 11.7 11.4 14.   8.2 13.2  6.1  8.  12.3  8.4 14.3  9.   8.7 10.6 13.1\n",
      " 10.7  5.5  5.8  6.8  8.8  8.5 13.8 11.5  7.3 13.7 12.8 13.4  6.3  3.1\n",
      " 17.  15.9 14.5 15.5 16.2 14.4 14.2 16.3 14.8 16.5 15.7 13.3 14.6 16.4\n",
      " 16.9 16.  14.7 16.6 14.9 16.7 16.8 15.8 15.1 17.1 17.2 15.3 17.3 17.4\n",
      " 17.7 17.8 17.5 17.6] values.\n",
      "\n",
      "pcv has [44. 38. 31. 32. 35. 39. 36. 33. 29. 28. nan 16. 24. 37. 30. 34. 40. 45.\n",
      " 27. 48. 52. 14. 22. 18. 42. 17. 46. 23. 19. 25. 41. 26. 15. 21. 43. 20.\n",
      " 47.  9. 49. 50. 53. 51. 54.] values.\n",
      "\n",
      "wc has [ 7800.  6000.  7500.  6700.  7300.    nan  6900.  9600. 12100.  4500.\n",
      " 12200. 11000.  3800. 11400.  5300.  9200.  6200.  8300.  8400. 10300.\n",
      "  9800.  9100.  7900.  6400.  8600. 18900. 21600.  4300.  8500. 11300.\n",
      "  7200.  7700. 14600.  6300.  7100. 11800.  9400.  5500.  5800. 13200.\n",
      " 12500.  5600.  7000. 11900. 10400. 10700. 12700.  6800.  6500. 13600.\n",
      " 10200.  9000. 14900.  8200. 15200.  5000. 16300. 12400. 10500.  4200.\n",
      "  4700. 10900.  8100.  9500.  2200. 12800. 11200. 19100. 12300. 16700.\n",
      "  2600. 26400.  8800.  7400.  4900.  8000. 12000. 15700.  4100.  5700.\n",
      " 11500.  5400. 10800.  9900.  5200.  5900.  9300.  9700.  5100.  6600.] values.\n",
      "\n",
      "rc has [5.2 nan 3.9 4.6 4.4 5.  4.  3.7 3.8 3.4 2.6 2.8 4.3 3.2 3.6 4.1 4.9 2.5\n",
      " 4.2 4.5 3.1 4.7 3.5 6.  2.1 5.6 2.3 2.9 2.7 8.  3.3 3.  2.4 4.8 5.4 6.1\n",
      " 6.2 6.3 5.1 5.8 5.5 5.3 6.4 5.7 5.9 6.5] values.\n",
      "\n",
      "htn has ['yes' 'no' nan] values.\n",
      "\n",
      "dm has ['yes' 'no' ' yes' '\\tno' '\\tyes' nan] values.\n",
      "\n",
      "cad has ['no' 'yes' '\\tno' nan] values.\n",
      "\n",
      "appet has ['good' 'poor' nan] values.\n",
      "\n",
      "pe has ['no' 'yes' nan] values.\n",
      "\n",
      "ane has ['no' 'yes' nan] values.\n",
      "\n",
      "classification has ['ckd' 'ckd\\t' 'notckd'] values.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    print(f'{col} has {df[col].unique()} values.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract numerical columns\n",
    "df_numeric = df.select_dtypes(exclude = 'object')\n",
    "\n",
    "#Extract catergorical columns\n",
    "df_category = df.select_dtypes(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the incorrect values with the correct values\n",
    "df['dm'] = df['dm'].replace({'\\tno':'no','\\tyes':'yes'})\n",
    "df['cad'] = df['cad'].replace({'\\tno':'no'})\n",
    "df['classification'] = df['classification'].replace({'ckd\\t':'ckd'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T01:16:54.288954Z",
     "start_time": "2019-05-27T01:16:54.283943Z"
    },
    "colab_type": "text",
    "id": "ysAGOB_cZBi4"
   },
   "source": [
    "#### Impute Null Values\n",
    "\n",
    "Impute null values for numeric and object columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.80000000e+01, 8.00000000e+01, 1.02000000e+00, ...,\n",
       "        4.40000000e+01, 7.80000000e+03, 5.20000000e+00],\n",
       "       [7.00000000e+00, 5.00000000e+01, 1.02000000e+00, ...,\n",
       "        3.80000000e+01, 6.00000000e+03, 4.70743494e+00],\n",
       "       [6.20000000e+01, 8.00000000e+01, 1.01000000e+00, ...,\n",
       "        3.10000000e+01, 7.50000000e+03, 4.70743494e+00],\n",
       "       ...,\n",
       "       [1.20000000e+01, 8.00000000e+01, 1.02000000e+00, ...,\n",
       "        4.90000000e+01, 6.60000000e+03, 5.40000000e+00],\n",
       "       [1.70000000e+01, 6.00000000e+01, 1.02500000e+00, ...,\n",
       "        5.10000000e+01, 7.20000000e+03, 5.90000000e+00],\n",
       "       [5.80000000e+01, 8.00000000e+01, 1.02500000e+00, ...,\n",
       "        5.30000000e+01, 6.80000000e+03, 6.10000000e+00]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imputing for numeric columns\n",
    "imp = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "imp.fit_transform(df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new dataframe with after imputer\n",
    "df_num = pd.DataFrame(data = imp.fit_transform(df_numeric), columns = df_numeric.columns, index = df_numeric.index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age     False\n",
       "bp      False\n",
       "sg      False\n",
       "al      False\n",
       "su      False\n",
       "bgr     False\n",
       "bu      False\n",
       "sc      False\n",
       "sod     False\n",
       "pot     False\n",
       "hemo    False\n",
       "pcv     False\n",
       "wc      False\n",
       "rc      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check missing values\n",
    "df_num.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing for categorical columns\n",
    "imp_cat = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "imp_cat.fit_transform(df_category)\n",
    "\n",
    "df_cat = pd.DataFrame(data = imp_cat.fit_transform(df_category), columns = df_category.columns, index = df_category.index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 11)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rbc               False\n",
       "pc                False\n",
       "pcc               False\n",
       "ba                False\n",
       "htn               False\n",
       "dm                False\n",
       "cad               False\n",
       "appet             False\n",
       "pe                False\n",
       "ane               False\n",
       "classification    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check missing values\n",
    "df_cat.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine Dataframe\n",
    "df_new = pd.merge(df_num, df_cat, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2t_0S5u8ZBi6"
   },
   "source": [
    "#### 3. Label Encoder\n",
    "\n",
    "Encode labels with value between 0 and n_classes-1.\n",
    "\n",
    "> from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbc have these ['normal' 'abnormal'] values\n",
      "\n",
      "pc have these ['normal' 'abnormal'] values\n",
      "\n",
      "pcc have these ['notpresent' 'present'] values\n",
      "\n",
      "ba have these ['notpresent' 'present'] values\n",
      "\n",
      "htn have these ['yes' 'no'] values\n",
      "\n",
      "dm have these ['yes' 'no' ' yes'] values\n",
      "\n",
      "cad have these ['no' 'yes'] values\n",
      "\n",
      "appet have these ['good' 'poor'] values\n",
      "\n",
      "pe have these ['no' 'yes'] values\n",
      "\n",
      "ane have these ['no' 'yes'] values\n",
      "\n",
      "classification have these ['ckd' 'notckd'] values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df_cat:\n",
    "    print(f'{col} have these {df_cat[col].unique()} values\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = df_cat.drop(columns = 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_new['classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T07:41:30.821964Z",
     "start_time": "2019-05-27T07:41:30.817976Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "o2LDxMC1ZBi6"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "y = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T02:01:36.412363Z",
     "start_time": "2019-05-27T02:01:36.408368Z"
    },
    "colab_type": "text",
    "id": "0r59fpVAZBi9"
   },
   "source": [
    "#### 4. OneHotEncoder \n",
    "\n",
    "Encode categorical integer features as a one-hot numeric array.\n",
    "\n",
    "The input to this transformer should be an array-like of integers or strings, denoting the values taken on by categorical (discrete) features. The features are encoded using a one-hot (aka ‘one-of-K’ or ‘dummy’) encoding scheme. This creates a binary column for each category and returns a sparse matrix or dense array.\n",
    "\n",
    "By default, the encoder derives the categories based on the unique values in each feature. Alternatively, you can also specify the categories manually. The OneHotEncoder previously assumed that the input features take on values in the range [0, max(values)). This behaviour is deprecated.\n",
    "\n",
    "This encoding is needed for feeding categorical data to many scikit-learn estimators, notably linear models and SVMs with the standard kernels.\n",
    "\n",
    "> from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T07:42:13.217369Z",
     "start_time": "2019-05-27T07:42:13.213356Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "fcOMDwFAZBi-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x0_abnormal' 'x0_normal' 'x1_abnormal' 'x1_normal' 'x2_notpresent'\n",
      " 'x2_present' 'x3_notpresent' 'x3_present' 'x4_no' 'x4_yes' 'x5_ yes'\n",
      " 'x5_no' 'x5_yes' 'x6_no' 'x6_yes' 'x7_good' 'x7_poor' 'x8_no' 'x8_yes'\n",
      " 'x9_no' 'x9_yes']\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(category)\n",
    "print(enc.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 21)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_enc = enc.transform(category)\n",
    "\n",
    "cat_enc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YM5nkSquZBjA"
   },
   "source": [
    "#### 5. Dummy Variables\n",
    "\n",
    "Convert categorical variable into dummy/indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T07:42:33.522386Z",
     "start_time": "2019-05-27T07:42:33.518397Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Q-znAG71ZBjB"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "\n",
    "X = df_new.drop(columns = 'classification')\n",
    "\n",
    "X = pd.get_dummies(X,drop_first = True)\n",
    "\n",
    "X = X.drop(columns = 'dm_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>hemo</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>rbc_normal</th>\n",
       "      <th>pc_normal</th>\n",
       "      <th>pcc_present</th>\n",
       "      <th>ba_present</th>\n",
       "      <th>htn_yes</th>\n",
       "      <th>dm_yes</th>\n",
       "      <th>cad_yes</th>\n",
       "      <th>appet_poor</th>\n",
       "      <th>pe_yes</th>\n",
       "      <th>ane_yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>15.4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.036517</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>11.3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4.707435</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>9.6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>4.707435</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>11.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>11.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>55.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>15.7</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>42.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>16.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>12.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>15.8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>6600.0</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>14.2</td>\n",
       "      <td>51.0</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>58.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>15.8</td>\n",
       "      <td>53.0</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age    bp     sg   al   su         bgr    bu   sc         sod       pot  \\\n",
       "id                                                                              \n",
       "0    48.0  80.0  1.020  1.0  0.0  121.000000  36.0  1.2  137.528754  4.627244   \n",
       "1     7.0  50.0  1.020  4.0  0.0  148.036517  18.0  0.8  137.528754  4.627244   \n",
       "2    62.0  80.0  1.010  2.0  3.0  423.000000  53.0  1.8  137.528754  4.627244   \n",
       "3    48.0  70.0  1.005  4.0  0.0  117.000000  56.0  3.8  111.000000  2.500000   \n",
       "4    51.0  80.0  1.010  2.0  0.0  106.000000  26.0  1.4  137.528754  4.627244   \n",
       "..    ...   ...    ...  ...  ...         ...   ...  ...         ...       ...   \n",
       "395  55.0  80.0  1.020  0.0  0.0  140.000000  49.0  0.5  150.000000  4.900000   \n",
       "396  42.0  70.0  1.025  0.0  0.0   75.000000  31.0  1.2  141.000000  3.500000   \n",
       "397  12.0  80.0  1.020  0.0  0.0  100.000000  26.0  0.6  137.000000  4.400000   \n",
       "398  17.0  60.0  1.025  0.0  0.0  114.000000  50.0  1.0  135.000000  4.900000   \n",
       "399  58.0  80.0  1.025  0.0  0.0  131.000000  18.0  1.1  141.000000  3.500000   \n",
       "\n",
       "     hemo   pcv      wc        rc  rbc_normal  pc_normal  pcc_present  \\\n",
       "id                                                                      \n",
       "0    15.4  44.0  7800.0  5.200000           1          1            0   \n",
       "1    11.3  38.0  6000.0  4.707435           1          1            0   \n",
       "2     9.6  31.0  7500.0  4.707435           1          1            0   \n",
       "3    11.2  32.0  6700.0  3.900000           1          0            1   \n",
       "4    11.6  35.0  7300.0  4.600000           1          1            0   \n",
       "..    ...   ...     ...       ...         ...        ...          ...   \n",
       "395  15.7  47.0  6700.0  4.900000           1          1            0   \n",
       "396  16.5  54.0  7800.0  6.200000           1          1            0   \n",
       "397  15.8  49.0  6600.0  5.400000           1          1            0   \n",
       "398  14.2  51.0  7200.0  5.900000           1          1            0   \n",
       "399  15.8  53.0  6800.0  6.100000           1          1            0   \n",
       "\n",
       "     ba_present  htn_yes  dm_yes  cad_yes  appet_poor  pe_yes  ane_yes  \n",
       "id                                                                      \n",
       "0             0        1       1        0           0       0        0  \n",
       "1             0        0       0        0           0       0        0  \n",
       "2             0        0       1        0           1       0        1  \n",
       "3             0        1       0        0           1       1        1  \n",
       "4             0        0       0        0           0       0        0  \n",
       "..          ...      ...     ...      ...         ...     ...      ...  \n",
       "395           0        0       0        0           0       0        0  \n",
       "396           0        0       0        0           0       0        0  \n",
       "397           0        0       0        0           0       0        0  \n",
       "398           0        0       0        0           0       0        0  \n",
       "399           0        0       0        0           0       0        0  \n",
       "\n",
       "[400 rows x 24 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1IrBuSXDZBjE"
   },
   "source": [
    "####  6. Set Target \n",
    "\n",
    "Set `classification` as target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "USH1cB-8ZBjE"
   },
   "source": [
    "#### 4. Select Feature\n",
    "\n",
    "The classes in the sklearn.feature_selection module can be used for feature selection/dimensionality reduction on sample sets, either to improve estimators’ accuracy scores or to boost their performance on very high-dimensional datasets.\n",
    "\n",
    "##### 4.1 Univariate Selection\n",
    "\n",
    "Univariate feature selection works by selecting the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator. Scikit-learn exposes feature selection routines as objects that implement the transform method:\n",
    "\n",
    "- SelectKBest removes all but the  highest scoring features\n",
    "- Use sklearn.feature_selection.chi2 as score function\n",
    "    > Recall that the chi-square test measures dependence between stochastic variables, so using this function “weeds out” the features that are the most likely to be independent of class and therefore irrelevant for classification.\n",
    "\n",
    "\n",
    "More Reads:\n",
    "[Univariate feature selection](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
    "\n",
    "- Create an instance of SelectKBest\n",
    "    - Use sklearn.feature_selection.chi2 as score_func\n",
    "    - Use k of your choice\n",
    "- Fit X, y \n",
    "- Find top 4 features\n",
    "- Transform features to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T07:43:18.924798Z",
     "start_time": "2019-05-27T07:43:18.920809Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "a_Q5N0oXZBjF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=3, score_func=<function chi2 at 0x7f841b9af040>)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "features = X.columns\n",
    "\n",
    "kbest = SelectKBest(chi2, k = 3)\n",
    "kbest.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.13462452e+02 8.00238633e+01 5.52366329e-03 2.28067797e+02\n",
      " 1.00951947e+02 2.42830358e+03 2.33600716e+03 3.54405935e+02\n",
      " 2.87966053e+01 4.05673770e+00 1.25101692e+02 3.24639089e+02\n",
      " 1.27337447e+04 2.08987247e+01 3.75467422e+00 1.06962963e+01\n",
      " 2.52000000e+01 1.32000000e+01 8.82000000e+01 8.16000000e+01\n",
      " 2.04000000e+01 4.92000000e+01 4.56000000e+01 3.60000000e+01]\n",
      "wc             12733.744679\n",
      "bgr             2428.303583\n",
      "bu              2336.007159\n",
      "sc               354.405935\n",
      "pcv              324.639089\n",
      "al               228.067797\n",
      "hemo             125.101692\n",
      "age              113.462452\n",
      "su               100.951947\n",
      "htn_yes           88.200000\n",
      "dm_yes            81.600000\n",
      "bp                80.023863\n",
      "appet_poor        49.200000\n",
      "pe_yes            45.600000\n",
      "ane_yes           36.000000\n",
      "sod               28.796605\n",
      "pcc_present       25.200000\n",
      "rc                20.898725\n",
      "cad_yes           20.400000\n",
      "ba_present        13.200000\n",
      "pc_normal         10.696296\n",
      "pot                4.056738\n",
      "rbc_normal         3.754674\n",
      "sg                 0.005524\n",
      "Name: K Score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(kbest.scores_)\n",
    "scores = kbest.scores_\n",
    "\n",
    "df_features = pd.DataFrame(data = scores, index = features, columns = ['K Score'])\n",
    "\n",
    "print(df_features['K Score'].sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4nfKmR0fZBjI"
   },
   "source": [
    "##### 4.2 Recursive feature elimination\n",
    "\n",
    "Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coef_ attribute or through a feature_importances_ attribute. Then, the least important features are pruned from current set of features.That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\n",
    "\n",
    "More Reads:\n",
    "[Recursive feature elimination](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
    "\n",
    "- Use RFE to extract feature\n",
    "    - use LogisticRegression as estimator\n",
    "    - Number of n_features_to_select as of your choice\n",
    "- Fit X, y to RFE\n",
    "- Find Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T07:43:33.184464Z",
     "start_time": "2019-05-27T07:43:33.180498Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "CooavWYMZBjI"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JohanNg/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/JohanNg/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/JohanNg/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/JohanNg/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/JohanNg/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/JohanNg/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/JohanNg/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/JohanNg/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/JohanNg/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/JohanNg/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/JohanNg/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(), n_features_to_select=3)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe = RFE(LogisticRegression(), n_features_to_select = 3)\n",
    "rfe.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rfe = pd.DataFrame({'Selected': rfe.support_,'Ranking': rfe.ranking_}, index = features, columns = ['Selected','Ranking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "al              1\n",
       "dm_yes          1\n",
       "htn_yes         1\n",
       "hemo            2\n",
       "rc              3\n",
       "rbc_normal      4\n",
       "su              5\n",
       "pe_yes          6\n",
       "sc              7\n",
       "appet_poor      8\n",
       "pc_normal       9\n",
       "pot            10\n",
       "ane_yes        11\n",
       "sg             12\n",
       "pcv            13\n",
       "sod            14\n",
       "bp             15\n",
       "bgr            16\n",
       "pcc_present    17\n",
       "cad_yes        18\n",
       "bu             19\n",
       "ba_present     20\n",
       "age            21\n",
       "wc             22\n",
       "Name: Ranking, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rfe['Ranking'].sort_values(ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UXKkl3LqZBjL"
   },
   "source": [
    "#### Create multiple Classifier Model\n",
    "\n",
    "Create multiple classifier models to predict the chronic kidney disease. Use any models of your choice. Evaluate all models and select the best model according to their performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5kDuGiLojfFe"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2019 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSIA_Lab_6_6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
