{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9X2kU2drQgj"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCm3ZQXVrQgm"
   },
   "source": [
    "# Lab 8.1: Bagging\n",
    "\n",
    "INSTRUCTIONS:\n",
    "\n",
    "- Read the guides and hints then create the necessary analysis and code to find an answer and conclusion for the scenario below.\n",
    "- The baseline results (minimum) are:\n",
    "    - **Accuracy** = 0.9667\n",
    "    - **ROC AUC**  = 0.9614\n",
    "- Try to achieve better results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "92pwAXoxrQgo"
   },
   "source": [
    "# Foreword\n",
    "It is common that companies and professionals start with the data immediately available. Although this approach works, ideally the first step is to identify the problem or question and only then identify and obtain the set of data that can help to solve or answer the problem.\n",
    "\n",
    "Also, given the current abundance of data, processing power and some particular machine learning methods, there could be a temptation to use ALL the data available. **Quality** is _**better**_ than **Quantity**!\n",
    "\n",
    "Part of calling this discipline **Data Science** is that it is supposed to follow a process and not reach conclusions without support from evidence.\n",
    "\n",
    "Moreover, it is a creative, exploratory, laborious, iterative and interactive process. It is part of the process to repeat, review and change when finding a dead-end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RSD00QfUrQgq"
   },
   "source": [
    "## Scenario: Predicting Breast Cancer\n",
    "The dataset you are going to be using for this laboratory is popularly known as the **Wisconsin Breast Cancer** dataset. The task related to it is Classification.\n",
    "\n",
    "The dataset contains a total number of _10_ features labelled in either **benign** or **malignant** classes. The features have _699_ instances out of which _16_ feature values are missing. The dataset only contains numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from mlxtend.plotting import plot_learning_curves\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yQBpCdC7rQgr"
   },
   "source": [
    "# Step 1: Define the problem or question\n",
    "Identify the subject matter and the given or obvious questions that would be relevant in the field.\n",
    "\n",
    "## Potential Questions\n",
    "List the given or obvious questions.\n",
    "\n",
    "## Actual Question\n",
    "Choose the **one** question that should be answered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a5EL9yvkrQgt"
   },
   "source": [
    "# Step 2: Find the Data\n",
    "### Wisconsin Breast Cancer DataSet\n",
    "- **Citation Request**\n",
    "\n",
    "    This breast cancer databases was obtained from the **University of Wisconsin Hospitals**, **Madison** from **Dr. William H. Wolberg**. If you publish results when using this database, then please include this information in your acknowledgements.\n",
    "\n",
    "- **Title**\n",
    "\n",
    "    Wisconsin Breast Cancer Database (January 8, 1991)\n",
    "\n",
    "- **Sources**\n",
    "    - **Creator**\n",
    "            Dr. William H. Wolberg (physician)\n",
    "            University of Wisconsin Hospitals\n",
    "            Madison, Wisconsin\n",
    "            USA\n",
    "    - **Donor**\n",
    "            Olvi Mangasarian (mangasarian@cs.wisc.edu)\n",
    "            Received by David W. Aha (aha@cs.jhu.edu)\n",
    "    - **Date**\n",
    "            15 July 1992\n",
    "        \n",
    "### UCI - Machine Learning Repository\n",
    "- Center for Machine Learning and Intelligent Systems\n",
    "\n",
    "The [**UCI Machine Learning Repository**](http://archive.ics.uci.edu/ml/about.html) is a collection of databases, domain theories, and data generators that are used by the machine learning community for the empirical analysis of machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29Y8teMmrQgu"
   },
   "source": [
    "# Step 3: Read the Data\n",
    "- Read the data\n",
    "- Perform some basic structural cleaning to facilitate the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('breast-cancer-wisconsin-data-old.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1000025</th>\n",
       "      <th>5</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>2</th>\n",
       "      <th>1.3</th>\n",
       "      <th>3</th>\n",
       "      <th>1.4</th>\n",
       "      <th>1.5</th>\n",
       "      <th>2.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017122</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1000025  5   1  1.1  1.2  2 1.3  3  1.4  1.5  2.1\n",
       "0  1002945  5   4    4    5  7  10  3    2    1    2\n",
       "1  1015425  3   1    1    1  2   2  3    1    1    2\n",
       "2  1016277  6   8    8    1  3   4  3    7    1    2\n",
       "3  1017023  4   1    1    3  2   1  3    1    1    2\n",
       "4  1017122  8  10   10    8  7  10  9    7    1    4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 698 entries, 0 to 697\n",
      "Data columns (total 11 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   1000025  698 non-null    int64 \n",
      " 1   5        698 non-null    int64 \n",
      " 2   1        698 non-null    int64 \n",
      " 3   1.1      698 non-null    int64 \n",
      " 4   1.2      698 non-null    int64 \n",
      " 5   2        698 non-null    int64 \n",
      " 6   1.3      698 non-null    object\n",
      " 7   3        698 non-null    int64 \n",
      " 8   1.4      698 non-null    int64 \n",
      " 9   1.5      698 non-null    int64 \n",
      " 10  2.1      698 non-null    int64 \n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 60.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['1000025'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This 5 have [ 5  3  6  4  8  1  2  7 10  9] values\n",
      "This 1 have [ 4  1  8 10  2  3  7  5  6  9] values\n",
      "This 1.1 have [ 4  1  8 10  2  3  5  6  7  9] values\n",
      "This 1.2 have [ 5  1  3  8 10  4  6  2  9  7] values\n",
      "This 2 have [ 7  2  3  1  6  4  5  8 10  9] values\n",
      "This 1.3 have ['10' '2' '4' '1' '3' '9' '7' '?' '5' '8' '6'] values\n",
      "This 3 have [ 3  9  1  2  4  5  7  8  6 10] values\n",
      "This 1.4 have [ 2  1  7  4  5  3 10  6  9  8] values\n",
      "This 1.5 have [ 1  5  4  2  3  7 10  8  6] values\n",
      "This 2.1 have [2 4] values\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    print(f'This {col} have {df[col].unique()} values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     401\n",
       "10    132\n",
       "2      30\n",
       "5      30\n",
       "3      28\n",
       "8      21\n",
       "4      19\n",
       "?      16\n",
       "9       9\n",
       "7       8\n",
       "6       4\n",
       "Name: 1.3, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['1.3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['1.3'].replace({'?':'1'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['1.3'] = df['1.3'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d-weYwx7rQgw"
   },
   "source": [
    "# Step 4: Explore and Clean the Data\n",
    "- Perform some initial simple **EDA** (Exploratory Data Analysis)\n",
    "- Check for\n",
    "    - **Number of features**\n",
    "    - **Data types**\n",
    "    - **Domains, Intervals**\n",
    "    - **Outliers** (are they valid or expurious data [read or measure errors])\n",
    "    - **Null** (values not present or coded [as zero of empty strings])\n",
    "    - **Missing Values** (coded [as zero of empty strings] or values not present)\n",
    "    - **Coded content** (classes identified by numbers or codes to represent absence of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This 5 have [ 5  3  6  4  8  1  2  7 10  9] values\n",
      "This 1 have [ 4  1  8 10  2  3  7  5  6  9] values\n",
      "This 1.1 have [ 4  1  8 10  2  3  5  6  7  9] values\n",
      "This 1.2 have [ 5  1  3  8 10  4  6  2  9  7] values\n",
      "This 2 have [ 7  2  3  1  6  4  5  8 10  9] values\n",
      "This 1.3 have [10  2  4  1  3  9  7  5  8  6] values\n",
      "This 3 have [ 3  9  1  2  4  5  7  8  6 10] values\n",
      "This 1.4 have [ 2  1  7  4  5  3 10  6  9  8] values\n",
      "This 1.5 have [ 1  5  4  2  3  7 10  8  6] values\n",
      "This 2.1 have [2 4] values\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    print(f'This {col} have {df[col].unique()} values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>2</th>\n",
       "      <th>1.3</th>\n",
       "      <th>3</th>\n",
       "      <th>1.4</th>\n",
       "      <th>1.5</th>\n",
       "      <th>2.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.416905</td>\n",
       "      <td>3.137536</td>\n",
       "      <td>3.210602</td>\n",
       "      <td>2.809456</td>\n",
       "      <td>3.217765</td>\n",
       "      <td>3.489971</td>\n",
       "      <td>3.438395</td>\n",
       "      <td>2.869628</td>\n",
       "      <td>1.590258</td>\n",
       "      <td>2.690544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.817673</td>\n",
       "      <td>3.052575</td>\n",
       "      <td>2.972867</td>\n",
       "      <td>2.856606</td>\n",
       "      <td>2.215408</td>\n",
       "      <td>3.623301</td>\n",
       "      <td>2.440056</td>\n",
       "      <td>3.055004</td>\n",
       "      <td>1.716162</td>\n",
       "      <td>0.951596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                5           1         1.1         1.2           2         1.3  \\\n",
       "count  698.000000  698.000000  698.000000  698.000000  698.000000  698.000000   \n",
       "mean     4.416905    3.137536    3.210602    2.809456    3.217765    3.489971   \n",
       "std      2.817673    3.052575    2.972867    2.856606    2.215408    3.623301   \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      2.000000    1.000000    1.000000    1.000000    2.000000    1.000000   \n",
       "50%      4.000000    1.000000    1.000000    1.000000    2.000000    1.000000   \n",
       "75%      6.000000    5.000000    5.000000    4.000000    4.000000    5.000000   \n",
       "max     10.000000   10.000000   10.000000   10.000000   10.000000   10.000000   \n",
       "\n",
       "                3         1.4         1.5         2.1  \n",
       "count  698.000000  698.000000  698.000000  698.000000  \n",
       "mean     3.438395    2.869628    1.590258    2.690544  \n",
       "std      2.440056    3.055004    1.716162    0.951596  \n",
       "min      1.000000    1.000000    1.000000    2.000000  \n",
       "25%      2.000000    1.000000    1.000000    2.000000  \n",
       "50%      3.000000    1.000000    1.000000    2.000000  \n",
       "75%      5.000000    4.000000    1.000000    4.000000  \n",
       "max     10.000000   10.000000   10.000000    4.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    457\n",
       "4    241\n",
       "Name: 2.1, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['2.1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.654728\n",
       "4    0.345272\n",
       "Name: 2.1, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['2.1'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6gt8rX8RrQgy"
   },
   "source": [
    "# Step 5: Prepare the Data\n",
    "- Deal with the data as required by the modelling technique\n",
    "    - **Outliers** (remove or adjust if possible or necessary)\n",
    "    - **Null** (remove or interpolate if possible or necessary)\n",
    "    - **Missing Values** (remove or interpolate if possible or necessary)\n",
    "    - **Coded content** (transform if possible or necessary [str to number or vice-versa])\n",
    "    - **Normalisation** (if possible or necessary)\n",
    "    - **Feature Engeneer** (if useful or necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['2.1'])\n",
    "y = df['2.1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z97YHdNerQgz"
   },
   "source": [
    "# Step 6: Modelling\n",
    "Refer to the Problem and Main Question.\n",
    "- What are the input variables (features)?\n",
    "- Is there an output variable (label)?\n",
    "- If there is an output variable:\n",
    "    - What is it?\n",
    "    - What is its type?\n",
    "- What type of Modelling is it?\n",
    "    - [ ] Supervised\n",
    "    - [ ] Unsupervised \n",
    "- What type of Modelling is it?\n",
    "    - [ ] Regression\n",
    "    - [ ] Classification (binary) \n",
    "    - [ ] Classification (multi-class)\n",
    "    - [ ] Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supervised, Binary Classification\n",
    "np.random.seed(0)\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 5)\n",
    "dt_clf = DecisionTreeClassifier(criterion = 'entropy', max_depth = 2, random_state =0)\n",
    "reg_clf = LogisticRegression(random_state = 0)\n",
    "svm_clf = svm.SVC(kernel = 'linear')\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "bagging_knn = BaggingClassifier(\n",
    "    base_estimator = knn_clf,\n",
    "    n_estimators = 10,\n",
    "    max_samples = 0.8,\n",
    "    max_features = 0.8)\n",
    "\n",
    "bagging_dt = BaggingClassifier(\n",
    "    base_estimator = dt_clf,\n",
    "    n_estimators = 10,\n",
    "    max_samples = 0.8,\n",
    "    max_features = 0.8)\n",
    "\n",
    "bagging_reg = BaggingClassifier(\n",
    "    base_estimator = reg_clf,\n",
    "    n_estimators = 10,\n",
    "    max_samples = 0.8,\n",
    "    max_features = 0.8)\n",
    "\n",
    "bagging_svm = BaggingClassifier(\n",
    "    base_estimator = svm_clf,\n",
    "    n_estimators = 10,\n",
    "    max_samples = 0.8,\n",
    "    max_features = 0.8)\n",
    "\n",
    "bagging_nb = BaggingClassifier(\n",
    "    base_estimator = nb_clf,\n",
    "    n_estimators = 10,\n",
    "    max_samples = 0.8,\n",
    "    max_features = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_61ti1HFrQg1"
   },
   "source": [
    "# Step 7: Split the Data\n",
    "\n",
    "Need to check for **Supervised** modelling:\n",
    "- Number of known cases or observations\n",
    "- Define the split in Training/Test or Training/Validation/Test and their proportions\n",
    "- Check for unbalanced classes and how to keep or avoid it when spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state =42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dsVE4u7GrQg3"
   },
   "source": [
    "# Step 8: Define and Fit Models\n",
    "\n",
    "Define the model and its hyper-parameters.\n",
    "\n",
    "Consider the parameters and hyper-parameters of each model at each (re)run and after checking the efficiency of a model against the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['K-NN', 'Decision Tree','Logistic Regression','SVM','Gaussian NB',\n",
    "         'Bagging K-NN', 'Bagging Tree','Bagging Logistic','Bagging SVM','Bagging NB']\n",
    "\n",
    "clf_list = [knn_clf, dt_clf,reg_clf,svm_clf,nb_clf,\n",
    "            bagging_knn, bagging_dt,bagging_reg,bagging_svm,bagging_nb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (10,8))\n",
    "gs = gridspec.GridSpec(5,2)\n",
    "grid = itertools.product([0,1],repeat = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train cross val: 0.9677 (+/- 0.0092) [K-NN]\n",
      "Accuracy for train: 0.9803 [K-NN]\n",
      "Accuracy for test: 0.9857 [K-NN]\n",
      "ROC/AUC Scores: 0.9812 [K-NN]\n",
      "\n",
      "Accuracy for train cross val: 0.9140 (+/- 0.0122) [Decision Tree]\n",
      "Accuracy for train: 0.9211 [Decision Tree]\n",
      "Accuracy for test: 0.9357 [Decision Tree]\n",
      "ROC/AUC Scores: 0.9275 [Decision Tree]\n",
      "\n",
      "Accuracy for train cross val: 0.9642 (+/- 0.0126) [Logistic Regression]\n",
      "Accuracy for train: 0.9677 [Logistic Regression]\n",
      "Accuracy for test: 0.9714 [Logistic Regression]\n",
      "ROC/AUC Scores: 0.9628 [Logistic Regression]\n",
      "\n",
      "Accuracy for train cross val: 0.9624 (+/- 0.0131) [SVM]\n",
      "Accuracy for train: 0.9677 [SVM]\n",
      "Accuracy for test: 0.9786 [SVM]\n",
      "ROC/AUC Scores: 0.9641 [SVM]\n",
      "\n",
      "Accuracy for train cross val: 0.9588 (+/- 0.0090) [Gaussian NB]\n",
      "Accuracy for train: 0.9552 [Gaussian NB]\n",
      "Accuracy for test: 0.9714 [Gaussian NB]\n",
      "ROC/AUC Scores: 0.9571 [Gaussian NB]\n",
      "\n",
      "Accuracy for train cross val: 0.9642 (+/- 0.0056) [Bagging K-NN]\n",
      "Accuracy for train: 0.9785 [Bagging K-NN]\n",
      "Accuracy for test: 0.9786 [Bagging K-NN]\n",
      "ROC/AUC Scores: 0.9786 [Bagging K-NN]\n",
      "\n",
      "Accuracy for train cross val: 0.9624 (+/- 0.0103) [Bagging Tree]\n",
      "Accuracy for train: 0.9588 [Bagging Tree]\n",
      "Accuracy for test: 0.9643 [Bagging Tree]\n",
      "ROC/AUC Scores: 0.9598 [Bagging Tree]\n",
      "\n",
      "Accuracy for train cross val: 0.9660 (+/- 0.0104) [Bagging Logistic]\n",
      "Accuracy for train: 0.9677 [Bagging Logistic]\n",
      "Accuracy for test: 0.9786 [Bagging Logistic]\n",
      "ROC/AUC Scores: 0.9641 [Bagging Logistic]\n",
      "\n",
      "Accuracy for train cross val: 0.9606 (+/- 0.0071) [Bagging SVM]\n",
      "Accuracy for train: 0.9677 [Bagging SVM]\n",
      "Accuracy for test: 0.9786 [Bagging SVM]\n",
      "ROC/AUC Scores: 0.9654 [Bagging SVM]\n",
      "\n",
      "Accuracy for train cross val: 0.9570 (+/- 0.0142) [Bagging NB]\n",
      "Accuracy for train: 0.9606 [Bagging NB]\n",
      "Accuracy for test: 0.9714 [Bagging NB]\n",
      "ROC/AUC Scores: 0.9650 [Bagging NB]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf, label in zip(clf_list,labels):\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv = 5, scoring = 'accuracy')\n",
    "    print('Accuracy for train cross val: %.4f (+/- %.4f) [%s]' % (scores.mean(), scores.std(), label))\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    print('Accuracy for train: %.4f [%s]' % (clf.score(X_train,y_train), label))\n",
    "    print('Accuracy for test: %.4f [%s]' % (clf.score(X_test,y_test), label))\n",
    "    yt_pred = clf.predict(X_train)\n",
    "    \n",
    "    print('ROC/AUC Scores: %.4f [%s]\\n' % (roc_auc_score(y_train,yt_pred),label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "48tgELX9rQg4"
   },
   "source": [
    "# Step 9: Verify and Evaluate the Training Model\n",
    "- Use the **training** data to make predictions\n",
    "- Check for overfitting\n",
    "- What metrics are appropriate for the modelling approach used\n",
    "- For **Supervised** models:\n",
    "    - Check the **Training Results** with the **Training Predictions** during development\n",
    "- Analyse, modify the parameters and hyper-parameters and repeat (within reason) until the model does not improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf.fit(X_train,y_train)\n",
    "\n",
    "params2 = {'n_neighbors':[2,5,10],\n",
    "          'weights':['uniform','distance'],\n",
    "          'algorithm': ['auto','brute','kd_tree','ball_tree'],\n",
    "          'leaf_size': [10,30,50]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.88 s, sys: 2.56 s, total: 4.44 s\n",
      "Wall time: 1.35 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(),\n",
       "             param_grid={'algorithm': ['auto', 'brute', 'kd_tree', 'ball_tree'],\n",
       "                         'leaf_size': [10, 30, 50], 'n_neighbors': [2, 5, 10],\n",
       "                         'weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid_knn = GridSearchCV(knn_clf,params2)\n",
    "\n",
    "grid_knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9677284427284427"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_knn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto', 'leaf_size': 30, 'n_neighbors': 5, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "bagging_knn.fit(X_train,y_train)\n",
    "\n",
    "params = {'n_estimators':[10,100],\n",
    "          'max_samples':[0.2,0.8,1.0],\n",
    "          'max_features': [0.2,0.8,1.0],\n",
    "          'bootstrap':[True,False],\n",
    "          'bootstrap_features':[True,False],\n",
    "          'random_state': [42]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.3 s, sys: 184 ms, total: 20.4 s\n",
      "Wall time: 20.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=BaggingClassifier(base_estimator=KNeighborsClassifier(),\n",
       "                                         max_features=0.8, max_samples=0.8),\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'bootstrap_features': [True, False],\n",
       "                         'max_features': [0.2, 0.8, 1.0],\n",
       "                         'max_samples': [0.2, 0.8, 1.0],\n",
       "                         'n_estimators': [10, 100], 'random_state': [42]})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid = GridSearchCV(bagging_knn,params)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9713481338481339"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=KNeighborsClassifier(),\n",
       "                  bootstrap_features=True, max_features=0.8, max_samples=0.8,\n",
       "                  random_state=42)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'bootstrap_features': True,\n",
       " 'max_features': 0.8,\n",
       " 'max_samples': 0.8,\n",
       " 'n_estimators': 10,\n",
       " 'random_state': 42}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WGKHPx9srQg6"
   },
   "source": [
    "# Step 10: Make Predictions and Evaluate the Test Model\n",
    "**NOTE**: **Do this only after not making any more improvements in the model**.\n",
    "\n",
    "- Use the **test** data to make predictions\n",
    "- For **Supervised** models:\n",
    "    - Check the **Test Results** with the **Test Predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iAz6pXN3rQg7"
   },
   "source": [
    "# Step 11: Solve the Problem or Answer the Question\n",
    "The results of an analysis or modelling can be used:\n",
    "- As part of a product or process, so the model can make predictions when new input data is available\n",
    "- As part of a report including text and charts to help understand the problem\n",
    "- As input for further questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > Â© 2021 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSIA Lab-8_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
